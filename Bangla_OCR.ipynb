{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bangla_OCR.ipynb","provenance":[],"authorship_tag":"ABX9TyNmQHai5uRjaRNP7Ahi8tNr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1aXFbw8TA2Pc"},"source":["import torch.utils.data as data\r\n","import cv2\r\n","import numpy as np\r\n","import os\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"slZGPT6zGij_"},"source":["path = '/content/full_traindata'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ryorw71eSc9A","colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"status":"error","timestamp":1611118089900,"user_tz":-480,"elapsed":1138,"user":{"displayName":"Mst. Shapna Akter 1721568042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjtzmt74JE60SL1ra0x1d0I85KcxoOGsZVLM_6b3g=s64","userId":"08525296820759733309"}},"outputId":"0f9504cb-2384-44fa-dd16-9f88b6bd1f91"},"source":["#extract zip file \r\n","\r\n","\r\n","import zipfile\r\n","file_name = \"/content/full_traindata.zip\"\r\n","with zipfile.ZipFile(file_name, 'r') as zip:\r\n","    zip.extractall()\r\n","   "],"execution_count":null,"outputs":[{"output_type":"error","ename":"BadZipFile","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-7a18bb5bf4d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/full_traindata.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGnZA6iJNJ9D","executionInfo":{"status":"ok","timestamp":1611117808274,"user_tz":-480,"elapsed":7456,"user":{"displayName":"Mst. Shapna Akter 1721568042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjtzmt74JE60SL1ra0x1d0I85KcxoOGsZVLM_6b3g=s64","userId":"08525296820759733309"}},"outputId":"0633911d-5b4c-4f5c-ae1b-d0fc26be2813"},"source":["!pip install python-Levenshtein==0.12.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'python-Levenshtein' candidate (version 0.12.0 at https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz#sha256=033a11de5e3d19ea25c9302d11224e1a1898fe5abd23c61c7c360c25195e3eb1 (from https://pypi.org/simple/python-levenshtein/))\n","Reason for being yanked: Insecure, upgrade to 0.12.1\u001b[0m\n","Collecting python-Levenshtein==0.12.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n","\r\u001b[K     |██████▊                         | 10kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 31.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 22.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein==0.12.0) (51.1.2)\n","Building wheels for collected packages: python-Levenshtein\n","  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144809 sha256=048a49257961f4ac37c7b0f4658046c84327e8a8bf3fac9c112ac69d4d130ce4\n","  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n","Successfully built python-Levenshtein\n","Installing collected packages: python-Levenshtein\n","Successfully installed python-Levenshtein-0.12.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"unRvJG0ANKqN"},"source":["\r\n","\r\n","#####################METRICS Functions############################################################\r\n","\r\n","\r\n","\r\n","#####################Function to calculate Average Edit Distance (NOT word error rate)############\r\n","\r\n","\r\n","#required for word error rate (WER)\r\n","#pip install python-Levenshtein\r\n","#preferred , pip install python-Levenshtein==0.12.0\r\n","import Levenshtein as Lev\r\n","\r\n","#WER functions\r\n","def compute_wer(predictions, labels):\r\n","    total_dist = 0\r\n","    \r\n","    #Check if prediction and original label are same\r\n","    assert len(predictions) == len(labels)\r\n","\r\n","    for i in range(len(predictions)):\r\n","        total_dist += Lev.distance(predictions[i], labels[i])\r\n","        #আমাার\r\n","        #তাামাার\r\n","        #abcd\r\n","        #abdfr\r\n","        #edit distance 1\r\n","\r\n","    word_error_rate = ( total_dist/len(predictions) )\r\n","\r\n","    return word_error_rate\r\n","\r\n","####################Metric which counts the number of words that absolutely match####################\r\n","\r\n","#Absolute matching function\r\n","def absolute_word_match(predictions, labels):\r\n","    count_correct = 0\r\n","    for x, y in zip(predictions, labels):\r\n","        #print(x)\r\n","        #print(y)\r\n","        if(x==y):\r\n","            count_correct += 1\r\n","    print(\"Absolute word match count is {}\".format(count_correct) )\r\n","\r\n","    return count_correct\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hphn_X7hNVMS"},"source":["\r\n","\r\n","###############################################Preprocessing functions#####################################\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","def preprocess_data(data_dir):\r\n","    grapheme_dict = {}\r\n","    labels = []\r\n","    words = []\r\n","    lengths = []\r\n","    count = 2\r\n","    filenames = os.listdir(data_dir)\r\n","    filenames = sorted(filenames, key=lambda x: int(x.split('_')[0]))\r\n","\r\n","    grapheme_dict['<eow>'] = 1\r\n","\r\n","    for i, name in enumerate(filenames):\r\n","        curr_word = name.split('_')[1][:-4]\r\n","        # print(curr_word)\r\n","        curr_label = []\r\n","        words.append(curr_word)\r\n","        graphemes = extract_graphemes(curr_word)\r\n","        # if 'স্ক্র্' in graphemes:\r\n","        #     print(curr_word)\r\n","        #     print(graphemes)\r\n","        for grapheme in graphemes:\r\n","            if grapheme not in grapheme_dict:\r\n","                grapheme_dict[grapheme] = count\r\n","                curr_label.append(count)\r\n","                count += 1\r\n","            else:\r\n","                curr_label.append(grapheme_dict[grapheme])\r\n","        lengths.append(len(curr_label))\r\n","        labels.append(curr_label)\r\n","    \r\n","\r\n","    inv_grapheme_dict = {v: k for k, v in grapheme_dict.items()}\r\n","    return grapheme_dict, inv_grapheme_dict, words, labels, lengths\r\n","\r\n","\r\n","#Backup, Imranul's 1st\r\n","###################################Decodes list of characters from it's numeric mapping################\r\n","\r\n","\r\n","def decode_prediction(preds, inv_grapheme_dict, raw = False):\r\n","    grapheme_list = []\r\n","    pred_list = []\r\n","    for i in range(len(preds)):\r\n","        if preds[i] != 0 and preds[i] != 1 and (not (i > 0 and preds[i - 1] == preds[i])):\r\n","            grapheme_list.append(inv_grapheme_dict.get(preds[i]))\r\n","            pred_list.append(preds[i])\r\n","\r\n","    return pred_list, ''.join(grapheme_list)\r\n","\r\n","\r\n","\r\n","####################################Extracts graphemes(letters) from dataset and throws away useless ones####\r\n","###################You can try to understand it but will require Bangla Grammer skills and good logic ######\r\n","############################################################################################################\r\n","\r\n","\r\n","def extract_graphemes(word):\r\n","    support_chars = ['্', 'ং', 'ঃ', 'ঁ', 'ি', 'ু', 'ূ', 'ৃ', 'ে', 'ো', 'ৌ' ,'ী', 'া', 'ে', 'ৈ']\r\n","    ref_chars = [ '্য', '্র', 'র্', 'য', 'র']\r\n","    unicode_garbage = ['\\x02', '\\x03', '\\x06', '\\x08', '\\x10', '\\x12', '&', '¡',\r\n","                        '¤', '¥', '¦', '©', '¬', '\\xad', '®', '¯', 'Ä', 'Í', 'ä', 'æ', 'è', 'ø', 'ÿ',\r\n","                        'œ', 'š', 'Ÿ', 'ƒ', 'β', '॥', '\\u09e4', '\\u200b', '\\u200d', '\\u200f', '\\uf020',\r\n","                        '\\uf02d', '�', '\\u200b', '\\u200c', '\\u09e5']\r\n","    \r\n","    chars = []\r\n","    i = 0\r\n","    prev_ref = False\r\n","\r\n","    while(i < len(word)):\r\n","        if word[i] != support_chars[0] and word[i] not in unicode_garbage:\r\n","            if i+1 < len(word):\r\n","                if word[i+1] != support_chars[0]:\r\n","                    if word[i+1] == ref_chars[-1] and i+2 < len(word):\r\n","                        if word[i+2] == support_chars[0]:\r\n","                            chars.append(word[i])\r\n","                            chars.append(ref_chars[2])\r\n","                            i += 2\r\n","                            prev_ref = True\r\n","                        else:\r\n","                            chars.append(word[i])\r\n","                            i += 1\r\n","                    else:\r\n","                        chars.append(word[i])\r\n","                        i += 1\r\n","                elif word[i+1] == support_chars[0] and word[i] not in support_chars[0:]:\r\n","                    previous = False\r\n","                    isSupport = True\r\n","                    idx = i+1\r\n","                    if idx<len(word):\r\n","                        while(isSupport):\r\n","                            if idx<len(word):\r\n","                                # print(word[i], word[idx], i, idx)\r\n","                                if (word[idx] == support_chars[0] or word[idx] == ref_chars[4]) and idx+1 < len(word):\r\n","                                    if word[idx] == support_chars[0] and word[idx-1] == ref_chars[-1]:\r\n","                                        if not previous:\r\n","                                            if i != idx:\r\n","                                                chars.append(word[i:(idx-1)])\r\n","                                            chars.append(ref_chars[2])\r\n","                                            idx += 1\r\n","                                            i = idx\r\n","                                            continue\r\n","                                    if word[idx] == ref_chars[-1]:\r\n","\r\n","                                        if word[idx+1] != support_chars[0]:\r\n","                                            chars.append(ref_chars[-1])\r\n","                                        idx += 1\r\n","                                        i = idx\r\n","                                        continue\r\n","                                    if word[idx+1] == ref_chars[3]:\r\n","                                        if i != idx:\r\n","                                            chars.append(word[i:idx])\r\n","                                        chars.append(ref_chars[0])\r\n","                                        idx += 2\r\n","                                        i = idx\r\n","                                        # print(i)\r\n","                                        # print(idx)\r\n","                                        continue\r\n","                                    if word[idx+1] == ref_chars[4]:\r\n","                                        # print(chars)\r\n","                                        if i != idx:\r\n","                                            chars.append(word[i:idx])\r\n","                                        chars.append(ref_chars[1])\r\n","                                        idx += 2\r\n","                                        i = idx\r\n","                                        previous = True\r\n","                                        continue\r\n","                                    if word[idx+1] == '\\u200c':\r\n","                                        if i != idx:\r\n","                                            chars.append(word[i:idx])\r\n","                                        i = idx+2\r\n","                                        isSupport = False\r\n","\r\n","                                    idx += 2\r\n","                                else:\r\n","                                    isSupport= False\r\n","                            else:\r\n","                                isSupport = False\r\n","                    if i != idx:\r\n","                        chars.append(word[i:idx])\r\n","                    i = idx\r\n","                else:\r\n","                    if word[i] in support_chars[0:]:\r\n","                        chars.append(word[i])\r\n","                    i += 2\r\n","            else:\r\n","                chars.append(word[i])\r\n","                i += 1\r\n","        else:\r\n","            if word[i]== support_chars[0]:\r\n","                if prev_ref:\r\n","                    prev_ref = False\r\n","                    i += 1\r\n","                    continue\r\n","                chars.append(word[i])\r\n","                i+=1\r\n","                continue\r\n","            else:\r\n","                i+=1\r\n","                continue\r\n","        \r\n","    return chars"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKBKs4uFNa35"},"source":["import torch.utils.data as data\r\n","import cv2\r\n","import numpy as np\r\n","import os\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEQdpbCJNepq"},"source":["\r\n","#########OCR Dataset Class###################################################\r\n","#########Helper functions to convert your images#############################\r\n","#########to the desired format###############################################\r\n","\r\n","class  OCRDataset(data.Dataset):\r\n","    def __init__(self, img_dir):\r\n","\r\n","        self.img_dir = img_dir\r\n","        # self.text_dir = text_dir\r\n","        self.inp_h = 32\r\n","        self.inp_w = 128\r\n","        self.mean = np.array(0.588, dtype=np.float32)\r\n","        self.std = np.array(0.193, dtype=np.float32)\r\n","        self.images = sorted(os.listdir(img_dir), key=lambda x: int(x.split('_')[0]))\r\n","\r\n","    def __len__(self):\r\n","        return len(self.images)\r\n","\r\n","    def __getitem__(self, idx):\r\n","        img_name = self.images[idx]\r\n","        # print(img_name)\r\n","        img = cv2.imread(os.path.join(self.img_dir, img_name))\r\n","        # print(img)\r\n","        \r\n","        #convert to greyscale\r\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n","\r\n","        img_h, img_w = img.shape\r\n","        \r\n","        #Resize to input size for network (32,128,1)\r\n","        img = cv2.resize(img, (0,0), fx=self.inp_w / img_w, fy=self.inp_h / img_h, interpolation=cv2.INTER_CUBIC)\r\n","        img = np.reshape(img, (self.inp_h, self.inp_w, 1))\r\n","\r\n","        #Normalize by mean and standard deviation\r\n","        img = img.astype(np.float32)\r\n","        # img = (img/255. - self.mean) / self.std\r\n","        \r\n","        #Reshape to tensor format supported by Pytorch (C, H, W)\r\n","        img = img.transpose([2, 0, 1])\r\n","        \r\n","        return img, img_name, idx\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8CSlqWuNig0"},"source":["############Helper function to pad your label lists######################################\r\n","############Get all necessary labels from your datasets#################################\r\n","\r\n","def get_padded_labels(idxs, grapheme_dict, inv_grapheme_dict, words, labels, lengths):\r\n","    batch_labels = []\r\n","    batch_lengths = []\r\n","    batch_words = []\r\n","    maxlen = 0\r\n","    for idx in idxs:\r\n","        batch_labels.append(labels[idx])\r\n","        batch_words.append(words[idx])\r\n","        batch_lengths.append(len(labels[idx]))\r\n","        maxlen = max(len(labels[idx]), maxlen)\r\n","    \r\n","    #changed [1]*(maxlen-len(batch_labels[i])) to [0]*(maxlen-len(batch_labels[i]))\r\n","    #Alls good\r\n","    for i in range(len(batch_labels)):\r\n","        batch_labels[i] = batch_labels[i] + [1]*(maxlen-len(batch_labels[i]))\r\n","\r\n","    return batch_words, batch_labels, batch_lengths, inv_grapheme_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O6v92qtGNmQq"},"source":["##Necessary Imports\r\n","\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GBadfkGzNpK3"},"source":["\r\n","\r\n","\r\n","#######################Some module that predicts sequences from the compacted feature rich version of ########\r\n","#######################image################################################################################\r\n","\r\n","\r\n","class BidirectionalLSTM(nn.Module):\r\n","    # Inputs hidden units Out\r\n","    def __init__(self, nIn, nHidden, nOut):\r\n","        super(BidirectionalLSTM, self).__init__()\r\n","\r\n","        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\r\n","        self.embedding = nn.Linear(nHidden * 2, nOut)\r\n","\r\n","    def forward(self, input):\r\n","        recurrent, _ = self.rnn(input)\r\n","        T, b, h = recurrent.size()\r\n","        t_rec = recurrent.view(T * b, h)\r\n","\r\n","        output = self.embedding(t_rec)  # [T * b, nOut]\r\n","        output = output.view(T, b, -1)\r\n","        # print(output.shape)\r\n","        return output\r\n","\r\n","\r\n","#######################Forward part is the real architecture. ################################\r\n","#######################The functions before that are used to #################################\r\n","#######################declare the feature extracting CNN    #################################\r\n","\r\n","class CRNN(nn.Module):\r\n","    def __init__(self, imgH, nc, nclass, nh, n_rnn=2, leakyRelu=False):\r\n","        super(CRNN, self).__init__()\r\n","        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\r\n","        \r\n","        \r\n","        #########################Convolutional Backbone Declaration############################\r\n","        \r\n","        \r\n","        ###kernel value for every layer\r\n","        ks = [3, 3, 3, 3, 3, 3, 2]\r\n","        \r\n","        ###padding value for every layer\r\n","        ps = [1, 1, 1, 1, 1, 1, 0]\r\n","        \r\n","        ###stride value for every layer\r\n","        ss = [1, 1, 1, 1, 1, 1, 1]\r\n","        \r\n","        ###channel value for every layer\r\n","        nm = [64, 128, 256, 256, 512, 512, 512]\r\n","        # w-k+2p/s\r\n","\r\n","        ##Sequential is good way to list layers one after another.\r\n","        ##To actually understand the syntax of Pytorch. we would\r\n","        ## suggest learning two things: \r\n","        \r\n","        ## Syntax of Python classes and objects\r\n","        ## https://www.youtube.com/watch?v=wfcWRAxRVBA&list=PLBZBJbE_rGRWeh5mIBhD-hhDwSEDxogDg&index=9\r\n","        \r\n","        ## For Pytorch, there's the official documents\r\n","        ## But this medium article is enough to be honest\r\n","        ## https://towardsdatascience.com/pytorch-how-and-when-to-use-module-sequential-modulelist-and-moduledict-7a54597b5f17\r\n","        \r\n","        \r\n","        cnn = nn.Sequential()\r\n","\r\n","        def convRelu(i, batchNormalization=False):\r\n","            nIn = nc if i == 0 else nm[i - 1]\r\n","            nOut = nm[i]\r\n","            cnn.add_module('conv{0}'.format(i),\r\n","                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\r\n","            if batchNormalization:\r\n","                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\r\n","            if leakyRelu:\r\n","                cnn.add_module('relu{0}'.format(i),\r\n","                               nn.LeakyReLU(0.2, inplace=True))\r\n","            else:\r\n","                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\r\n","\r\n","        convRelu(0)\r\n","        \r\n","        ##Output shape is 512X1X33\r\n","        ##(Batch X Height X Width)\r\n","        # bs, 32, 128\r\n","        # 512, 16, 1\r\n","        \r\n","        \r\n","        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2)) \r\n","        convRelu(1)\r\n","        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2)) \r\n","        convRelu(2, True)\r\n","        convRelu(3)\r\n","        cnn.add_module('pooling{0}'.format(2),\r\n","                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))\r\n","        convRelu(4, True)\r\n","        convRelu(5)\r\n","        cnn.add_module('pooling{0}'.format(3),\r\n","                       nn.MaxPool2d((2, 2), (2, 1), (0, 1))) \r\n","        convRelu(6, True)  # 512x1x33\r\n","\r\n","        self.cnn = cnn\r\n","        \r\n","        \r\n","        #########################Convolutional Backbone Declaration############################\r\n","        \r\n","        \r\n","        \r\n","        #########################Inherit LSTM function from LSTM function######################\r\n","        \r\n","        self.rnn = nn.Sequential(\r\n","            BidirectionalLSTM(512, nh, nh),\r\n","            BidirectionalLSTM(nh, nh, nclass))\r\n","        \r\n","        #########################Inherit LSTM function from LSTM function######################\r\n","\r\n","    def forward(self, input):\r\n","\r\n","        #input is the input image in (Batch, Channel, Height, Width) form\r\n","        \r\n","        \r\n","        #conv = Feature extracted by Convolutional Network\r\n","        conv = self.cnn(input)\r\n","        \r\n","        \r\n","        #######convert feature(conv) so LSTM can read it##################\r\n","        \r\n","        b, c, h, w = conv.size()\r\n","        #print(conv.shape)\r\n","        #make sure height is 1, we will predicting along the sequnce\r\n","        assert h == 1, \"the height of conv must be 1\"\r\n","        \r\n","        \r\n","        conv = conv.squeeze(2) # b *512 * width\r\n","        conv = conv.permute(2, 0, 1)  # [w, b, c]\r\n","        \r\n","        #############################################################\r\n","        \r\n","        \r\n","        #############Send to LSTM then###############################\r\n","        #############softmax it to get ##############################\r\n","        #############probability between 0 and 1#####################\r\n","        ###Softmax across dimension 2 because it will have###########\r\n","        ####288 possible labels and they will have values############\r\n","        ####(probability distribution)(between 0 and 1)##############\r\n","        output = F.log_softmax(self.rnn(conv), dim=2)\r\n","\r\n","        return output\r\n","\r\n","    \r\n","###########weight initialization helps model achieve better###########\r\n","#############gradients gradually, experiment with HE intialization####\r\n","#############Xavier init etc, if possible#############################\r\n","def weights_init(m):\r\n","    classname = m.__class__.__name__\r\n","    if classname.find('Conv') != -1:\r\n","        m.weight.data.normal_(0.0, 0.02)\r\n","    elif classname.find('BatchNorm') != -1:\r\n","        m.weight.data.normal_(1.0, 0.02)\r\n","        m.bias.data.fill_(0)\r\n","\r\n","        \r\n","#####Send model after intializing weight##############################        \r\n","def get_crnn():\r\n","    \r\n","    #(Initial Image Height, Feature Height, Labels, LSTM hidden Layer)\r\n","    model = CRNN(32, 1, 34, 256)\r\n","    model.apply(weights_init)\r\n","\r\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vVv_cTYJNtLE"},"source":["##Necessary Imports\r\n","\r\n","\r\n","import torch\r\n","from sklearn.metrics import classification_report\r\n","from sklearn.metrics import accuracy_score\r\n","from sklearn.metrics import f1_score\r\n","import numpy as np\r\n","from tqdm import tqdm\r\n","import torch.optim as optim\r\n","from torch.utils.data.sampler import SubsetRandomSampler\r\n","\r\n","import json\r\n","import pickle\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1FSgwg2LffYr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HZ17Ps94Nw0g","executionInfo":{"status":"error","timestamp":1611117979839,"user_tz":-480,"elapsed":1222,"user":{"displayName":"Mst. Shapna Akter 1721568042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjtzmt74JE60SL1ra0x1d0I85KcxoOGsZVLM_6b3g=s64","userId":"08525296820759733309"}},"outputId":"7d703933-7cee-4112-c09d-3d3464377cb0"},"source":["#Retrieve Model and print model\r\n","\r\n","model = get_crnn()\r\n","model = model.cuda()\r\n","print(model)\r\n","\r\n","#########Counting Model Parameters#######################\r\n","\r\n","#counting parameters\r\n","def count_parameters(model):\r\n","    for name, param in model.named_parameters():\r\n","        if param.requires_grad:\r\n","            print(name, param.numel())\r\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n","\r\n","\r\n","print(count_parameters(model))\r\n","##########################################################\r\n","\r\n","\r\n","###############Continuation of training###################\r\n","\r\n","#Path to model, if you encounter loadshedding.\r\n","#And want to continue training\r\n","#model.load_state_dict(torch.load('path/to/model.pth'))\r\n","\r\n","##########################################################\r\n","\r\n","\r\n","#########################Loss function decalaration############################\r\n","\r\n","\r\n","#Zero inifinity problem, gradient collapses to zero, when 287 labels\r\n","criterion = torch.nn.CTCLoss(blank =0, reduction='mean', zero_infinity = True)\r\n","criterion = criterion.cuda()\r\n","#[1,1,1,1,1,10,10,4,4]\r\n","#[]\r\n","#[1,10,4]\r\n","\r\n","###############################################################################\r\n","\r\n","\r\n","\r\n","#################Extract and Preprocess dataset################################\r\n","\r\n","##Example::\r\n","##ocr_dataset = OCRDataset('/home/imr555/Desktop/Apurba_Job/Day_14/wlbocrv3/out_50000')\r\n","ocr_dataset = OCRDataset(path)\r\n","\r\n","\r\n","##Example::\r\n","##grapheme_dict_i, inv_grapheme_dict_i, words_i, labels_i, lengths_i = preprocess_data('/home/imr555/Desktop/Apurba_Job/Day_14/wlbocrv3/out_50000')\r\n","grapheme_dict_i, inv_grapheme_dict_i, words_i, labels_i, lengths_i = preprocess_data('/content/full_traindata')\r\n","\r\n","#print(grapheme_dict_i)\r\n","#print(len(grapheme_dict_i))\r\n","#sanity check\r\n","#print(words_i)\r\n","#print(labels_i)\r\n","\r\n","#################################################################################\r\n","\r\n","\r\n","\r\n","\r\n","#######################Setting validation and train split########################\r\n","\r\n","\r\n","validation_split = .2\r\n","shuffle_dataset = True\r\n","random_seed= 42\r\n","\r\n","#seeding for reproducability\r\n","torch.manual_seed(random_seed)\r\n","\r\n","# Creating data indices for training and validation splits\r\n","dataset_size = len(ocr_dataset)\r\n","indices = list(range(dataset_size))\r\n","split = int(np.floor(validation_split * dataset_size))\r\n","if shuffle_dataset :\r\n","    np.random.seed(random_seed)\r\n","    np.random.shuffle(indices)\r\n","train_indices, val_indices = indices[split:], indices[:split]\r\n","\r\n","train_sampler = SubsetRandomSampler(train_indices)\r\n","valid_sampler = SubsetRandomSampler(val_indices)\r\n","\r\n","#Batch Size variable (Decrease it if you hit memory error, or increase it for faster train)\r\n","train_batch_s = 32\r\n","valid_batch_s = 32\r\n","\r\n","train_loader = torch.utils.data.DataLoader(ocr_dataset, batch_size= train_batch_s, \r\n","                                           sampler=train_sampler)\r\n","validation_loader = torch.utils.data.DataLoader(ocr_dataset, batch_size= valid_batch_s,\r\n","                                                sampler=valid_sampler)\r\n","\r\n","\r\n","\r\n","\r\n","#################################################################################"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CRNN(\n","  (cnn): Sequential(\n","    (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (relu0): ReLU(inplace=True)\n","    (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (relu1): ReLU(inplace=True)\n","    (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu2): ReLU(inplace=True)\n","    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (relu3): ReLU(inplace=True)\n","    (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n","    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu4): ReLU(inplace=True)\n","    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (relu5): ReLU(inplace=True)\n","    (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n","    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n","    (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu6): ReLU(inplace=True)\n","  )\n","  (rnn): Sequential(\n","    (0): BidirectionalLSTM(\n","      (rnn): LSTM(512, 256, bidirectional=True)\n","      (embedding): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","    (1): BidirectionalLSTM(\n","      (rnn): LSTM(256, 256, bidirectional=True)\n","      (embedding): Linear(in_features=512, out_features=34, bias=True)\n","    )\n","  )\n",")\n","cnn.conv0.weight 576\n","cnn.conv0.bias 64\n","cnn.conv1.weight 73728\n","cnn.conv1.bias 128\n","cnn.conv2.weight 294912\n","cnn.conv2.bias 256\n","cnn.batchnorm2.weight 256\n","cnn.batchnorm2.bias 256\n","cnn.conv3.weight 589824\n","cnn.conv3.bias 256\n","cnn.conv4.weight 1179648\n","cnn.conv4.bias 512\n","cnn.batchnorm4.weight 512\n","cnn.batchnorm4.bias 512\n","cnn.conv5.weight 2359296\n","cnn.conv5.bias 512\n","cnn.conv6.weight 1048576\n","cnn.conv6.bias 512\n","cnn.batchnorm6.weight 512\n","cnn.batchnorm6.bias 512\n","rnn.0.rnn.weight_ih_l0 524288\n","rnn.0.rnn.weight_hh_l0 262144\n","rnn.0.rnn.bias_ih_l0 1024\n","rnn.0.rnn.bias_hh_l0 1024\n","rnn.0.rnn.weight_ih_l0_reverse 524288\n","rnn.0.rnn.weight_hh_l0_reverse 262144\n","rnn.0.rnn.bias_ih_l0_reverse 1024\n","rnn.0.rnn.bias_hh_l0_reverse 1024\n","rnn.0.embedding.weight 131072\n","rnn.0.embedding.bias 256\n","rnn.1.rnn.weight_ih_l0 262144\n","rnn.1.rnn.weight_hh_l0 262144\n","rnn.1.rnn.bias_ih_l0 1024\n","rnn.1.rnn.bias_hh_l0 1024\n","rnn.1.rnn.weight_ih_l0_reverse 262144\n","rnn.1.rnn.weight_hh_l0_reverse 262144\n","rnn.1.rnn.bias_ih_l0_reverse 1024\n","rnn.1.rnn.bias_hh_l0_reverse 1024\n","rnn.1.embedding.weight 17408\n","rnn.1.embedding.bias 34\n","8329762\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-be571e14be7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m##Example::\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m##ocr_dataset = OCRDataset('/home/imr555/Desktop/Apurba_Job/Day_14/wlbocrv3/out_50000')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mocr_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOCRDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-c58e7c9bcaf8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_dir)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.588\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.193\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/full_traindata'"]}]},{"cell_type":"code","metadata":{"id":"oGDGj9dBf6QN"},"source":["\r\n","validation_split = .2\r\n","shuffle_dataset = True\r\n","random_seed= 42\r\n","\r\n","#seeding for reproducability\r\n","torch.manual_seed(random_seed)\r\n","\r\n","# Creating data indices for training and validation splits\r\n","dataset_size = len(ocr_dataset)\r\n","indices = list(range(dataset_size))\r\n","split = int(np.floor(validation_split * dataset_size))\r\n","if shuffle_dataset :\r\n","    np.random.seed(random_seed)\r\n","    np.random.shuffle(indices)\r\n","train_indices, val_indices = indices[split:], indices[:split]\r\n","\r\n","train_sampler = SubsetRandomSampler(train_indices)\r\n","valid_sampler = SubsetRandomSampler(val_indices)\r\n","\r\n","#Batch Size variable (Decrease it if you hit memory error, or increase it for faster train)\r\n","train_batch_s = 32\r\n","valid_batch_s = 32\r\n","\r\n","train_loader = torch.utils.data.DataLoader(ocr_dataset, batch_size= train_batch_s, \r\n","                                           sampler=train_sampler)\r\n","validation_loader = torch.utils.data.DataLoader(ocr_dataset, batch_size= valid_batch_s,\r\n","                                                sampler=valid_sampler)\r\n","\r\n","\r\n","\r\n","\r\n","#################################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLqWD21wN2Ij"},"source":["def train(metrics1, metrics2):\r\n","    \r\n","    ###Set epoch number here\r\n","    for epoch in range(15):\r\n","        print(\"***Epoch: {}***\".format(epoch))\r\n","        batch_loss = 0\r\n","        #change this for epoch\r\n","        if epoch>7:\r\n","            optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0003)\r\n","        else:\r\n","            optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\r\n","        for i, (inp, img_names, idx) in enumerate(tqdm(train_loader)):\r\n","            inp = inp.cuda()\r\n","            batch_size = inp.size(0)\r\n","            idxs = idx.detach().numpy()\r\n","            img_names = list(img_names)\r\n","            words, labels, labels_size, inv_grapheme_dict = get_padded_labels(idxs, grapheme_dict_i, inv_grapheme_dict_i, words_i, labels_i, lengths_i)\r\n","            preds = model(inp)\r\n","            labels = torch.tensor(labels, dtype=torch.long)\r\n","            labels = labels.cuda()\r\n","            labels_size = torch.tensor(labels_size, dtype=torch.long)\r\n","            labels_size = labels_size.cuda()\r\n","            preds_size = torch.tensor([preds.size(0)] * batch_size, dtype=torch.long)\r\n","            preds_size = preds_size.cuda()\r\n","            loss = criterion(preds, labels, preds_size, labels_size)\r\n","            #print(loss.item())\r\n","            batch_loss += loss.item()\r\n","\r\n","            optimizer.zero_grad()\r\n","            loss.backward()\r\n","            optimizer.step()\r\n","\r\n","        train_loss = batch_loss/train_batch_s\r\n","        print(\"Epoch Training loss: \", train_loss) #batch_size denominator 32\r\n","        \r\n","\r\n","        print(\"\\n\")\r\n","        validate(epoch, metrics1, metrics2, train_loss)\r\n","        #if epoch%1 == 0:\r\n","        torch.save(model.state_dict(), 'epoch{}.pth'.format(epoch))\r\n","\r\n","def validate(epoch, metrics1, metrics2, train_loss):\r\n","    with torch.no_grad():\r\n","        y_true = []\r\n","        y_pred = []\r\n","        pred_ = []\r\n","        label_ = []\r\n","\r\n","        total_wer = 0\r\n","\r\n","        print(\"***Epoch: {}***\".format(epoch))\r\n","        batch_loss = 0\r\n","        for i, (inp, img_names, idx) in enumerate(tqdm(validation_loader)):\r\n","            inp = inp.cuda()\r\n","            batch_size = inp.size(0)\r\n","            idxs = idx.detach().numpy()\r\n","            img_names = list(img_names)\r\n","            words, labels, labels_size, inv_grapheme_dict = get_padded_labels(idxs, grapheme_dict_i, inv_grapheme_dict_i, words_i, labels_i, lengths_i)\r\n","            preds = model(inp)\r\n","            labels = torch.tensor(labels, dtype=torch.long)\r\n","            labels = labels.cuda()\r\n","            labels_size = torch.tensor(labels_size, dtype=torch.long)\r\n","            labels_size = labels_size.cuda()\r\n","            preds_size = torch.tensor([preds.size(0)] * batch_size, dtype=torch.long) \r\n","            preds_size = preds_size.cuda()\r\n","\r\n","            #validation loss\r\n","            loss = criterion(preds, labels, preds_size, labels_size)\r\n","            print(loss)\r\n","            batch_loss += loss.item()\r\n","            print(loss.item())\r\n","\r\n","            _, preds = preds.max(2)\r\n","            preds = preds.transpose(1, 0).contiguous().detach().cpu().numpy()\r\n","            preds = np.argmax(preds, axis=1)\r\n","            labels = labels.detach().numpy()\r\n","            \r\n","            for i in range(len(preds)):\r\n","                decoded, _ = decode_prediction(preds[i], inv_grapheme_dict)\r\n","                for x,y in zip(decoded, labels[i]):\r\n","                    y_pred.append(x)\r\n","                    y_true.append(y)\r\n","                _, decoded_pred_ = decode_prediction(preds[i], inv_grapheme_dict)\r\n","                #print(inv_grapheme_dict)\r\n","                _, decoded_label_ = decode_prediction(labels[i], inv_grapheme_dict)\r\n","                #print(decoded_label_)\r\n","                \r\n","                pred_.append(decoded_pred_)\r\n","                label_.append(decoded_label_)\r\n","\r\n","        valid_loss = batch_loss/valid_batch_s\r\n","        print(\"Epoch Validation loss: \", valid_loss) #batch_size denominator 32\r\n","        print(\"\\n\")\r\n","        #print(pred_)\r\n","        #print(label_)\r\n","        total_wer = compute_wer(pred_, label_)\r\n","        print(\"Total_Word_Error_Rate: %.4f\" % total_wer)\r\n","\r\n","        #change in number of labels\r\n","        # [5,6,3,2]\r\n","        # [2,6,3,1]\r\n","        report = classification_report(y_true, y_pred, labels = np.arange(1,34), zero_division=0)\r\n","        f1_micro = f1_score(y_true, y_pred, average = 'micro', zero_division=0)\r\n","        f1_macro = f1_score(y_true, y_pred, average = 'macro', zero_division=0)\r\n","        accuracy = accuracy_score(y_true, y_pred)\r\n","        \r\n","\r\n","        #Absolute word matching\r\n","        abs_correct = absolute_word_match(pred_, label_)\r\n","\r\n","\r\n","\r\n","        with open('Results__Report_epoch{}.txt'.format(epoch), 'w') as fout2:\r\n","            fout2.write(report)\r\n","\r\n","\r\n","        with open('results.txt', 'w') as fout:\r\n","            for x,y in zip(pred_, label_):\r\n","                fout.write(\"True: {}\".format(y))\r\n","                fout.write(\"\\n\")\r\n","                fout.write(\"Pred: {}\".format(x))\r\n","                fout.write(\"\\n\\n\")\r\n","        print(\"Accuracy: %.4f\" % accuracy)\r\n","        print(\"F1 Micro Score: %.4f\" % f1_micro)\r\n","        print(\"F1 Macro Score: %.4f\" % f1_macro)\r\n","        print(\"\\n\")\r\n","\r\n","        ################################################JSON Dumps\r\n","        metrics1['epoch'].append(epoch)\r\n","        metrics1['accuracy'].append(accuracy)\r\n","        metrics1['train_loss'].append(train_loss)\r\n","        metrics1['valid_loss'].append(valid_loss)\r\n","        metrics1['total_wer'].append(total_wer)\r\n","        metrics1['f1_micro'].append(f1_micro)\r\n","        metrics1['f1_macro'].append(f1_macro)\r\n","        metrics1['absolute_word_correct'].append(abs_correct)\r\n","\r\n","        json.dump( metrics1, open( \"metrics(general).json\", 'w' ))\r\n","\r\n","        metrics2['epoch'].append(epoch)\r\n","        metrics2['report'].append(report)\r\n","\r\n","        json.dump( metrics2, open( \"metrics(report).json\", 'w' ))\r\n","\r\n","\r\n","        print(\"End of Epoch {}\".format(epoch))\r\n","        print(\"\\n\\n\")\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"hzEtSfuKN8Ah","executionInfo":{"status":"error","timestamp":1611058418940,"user_tz":-480,"elapsed":982,"user":{"displayName":"Mst. Shapna Akter 1721568042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjtzmt74JE60SL1ra0x1d0I85KcxoOGsZVLM_6b3g=s64","userId":"08525296820759733309"}},"outputId":"9df38c08-810f-4de6-8d14-8941ca26ba10"},"source":["metrics1 = {\r\n","'epoch': [],\r\n","'accuracy': [],\r\n","'train_loss': [],\r\n","'valid_loss': [],\r\n","'total_wer': [],\r\n","'f1_micro': [],\r\n","'f1_macro': [],\r\n","'absolute_word_correct': [],\r\n","}\r\n","\r\n","metrics2 = {\r\n","'epoch': [],\r\n","'report': [],\r\n","}\r\n","\r\n","train(metrics1, metrics2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/767 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["***Epoch: 0***\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-b0a64a38d3f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-61-1e43dd59251c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(metrics1, metrics2)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mimg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_grapheme_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_padded_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrapheme_dict_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_grapheme_dict_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-52-8dd2827ebbfd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m#conv = Feature extracted by Convolutional Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"]}]},{"cell_type":"code","metadata":{"id":"O68gW51EkTV8"},"source":[" "],"execution_count":null,"outputs":[]}]}